import streamlit as st
from langchain.agents import ConversationalChatAgent, AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI

# è®¾ç½® Streamlit é¡µé¢é…ç½®
st.set_page_config(page_title="Llama3 ChatBot with Search", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ Llama3: Chat with Search")

# è·å– API key å’Œ base URLï¼ˆä¼˜å…ˆä» secrets è·å–ï¼Œå…¶æ¬¡ä»ç”¨æˆ·è¾“å…¥ï¼‰
openai_api_key = st.sidebar.text_input("API Key", type="password")

api_model_name = st.sidebar.text_input("æ¨¡å‹(å¯é€‰)", value="rohan/Meta-Llama-3-70B-Instruct")

# æ˜¾ç¤ºä¿¡æ¯å’Œé“¾æ¥
with st.sidebar:
    st.markdown("[llama3 API Keyè·å–æ–¹å¼](https://nbid.bid/blog)")

# åˆå§‹åŒ–èŠå¤©å†å²å’Œå†…å­˜
msgs = StreamlitChatMessageHistory()
memory = ConversationBufferMemory(
    chat_memory=msgs,
    return_messages=True,
    memory_key="chat_history",
    output_key="output"
)

# é‡ç½®èŠå¤©å†å²æŒ‰é’®
if len(msgs.messages) == 0 or st.sidebar.button("Reset Chat History"):
    msgs.clear()
    msgs.add_ai_message("è¯·è¾“å…¥â€¦â€¦")
    st.session_state.steps = {}

# æ˜¾ç¤ºèŠå¤©å†å²ï¼ŒåŒ…æ‹¬ä¸­é—´æ­¥éª¤
avatars = {"human": "user", "ai": "assistant"}
for idx, msg in enumerate(msgs.messages):
    with st.chat_message(avatars[msg.type]):
        for step in st.session_state.steps.get(str(idx), []):
            if step[0].tool == "_Exception":
                continue
            with st.status(f"**{step[0].tool}**: {step[0].tool_input}", state="complete"):
                st.write(step[0].log)
                st.write(step[1])
        st.write(msg.content)

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input(placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜"):
    st.chat_message("user").write(prompt)

    # æ£€æŸ¥ API Key
    if not openai_api_key:
        st.error("è¯·æ·»åŠ æ‚¨çš„ API key ä»¥ç»§ç»­ã€‚")
        st.stop()
    
    # åˆå§‹åŒ– LangChain èŠå¤©æœºå™¨äººå’Œå·¥å…·

    llm = ChatOpenAI(
        model_name=api_model_name,
        openai_api_key=openai_api_key,
        openai_api_base=openai_api_base,
        streaming=True
    )
    tools = [DuckDuckGoSearchRun(name="Search")]
    chat_agent = ConversationalChatAgent.from_llm_and_tools(llm=llm, tools=tools)
    executor = AgentExecutor.from_agent_and_tools(
        agent=chat_agent,
        tools=tools,
        memory=memory,
        return_intermediate_steps=True,
        handle_parsing_errors=True,
    )

    # æ‰§è¡ŒèŠå¤©æœºå™¨äººå¹¶æ˜¾ç¤ºå“åº”ï¼ŒåŒ…æ‹¬é”™è¯¯å¤„ç†
    with st.chat_message("assistant"):
        st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)
        cfg = RunnableConfig()
        cfg["callbacks"] = [st_cb]
        try:
            response = executor.invoke(prompt, cfg)
            st.write(response["output"])
            st.session_state.steps[str(len(msgs.messages) - 1)] = response["intermediate_steps"]
        except Exception as e:
            st.error(f"æ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
